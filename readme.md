# UCS761 â€“ Deep Learning Lab Assignments

This repository contains my solutions to selected **Deep Learning laboratory assignments** for the course **UCS761**.  
The main objective of these experiments is to strengthen conceptual understanding by implementing core machine learning models **from scratch using NumPy**, without using high-level deep learning libraries.

---

## ðŸ“ Repository Structure
```
â”œâ”€â”€ Logistic_Regression_Soft_Decision_Model.ipynb
â”œâ”€â”€ Multi_Linear_Regression_via_Linear_Perceptron.ipynb
â”œâ”€â”€ README.md
```

---

## ðŸ§ª Experiment 1: Logistic Regression as a Soft Decision Model

ðŸ“˜ **Notebook:**  
`Logistic_Regression_Soft_Decision_Model.ipynb`

### Objective
To analyze logistic regression as a **probability-based classification model** and understand how it improves upon hard decision models like the perceptron.

### Topics Covered
- Sigmoid activation and probability outputs
- Binary Cross-Entropy loss
- Gradient Descent optimization
- Effect of varying decision thresholds
- Comparison between perceptron and logistic regression

---

## ðŸ§ª Experiment 2: Multiple Linear Regression using Linear Perceptron

ðŸ“˜ **Notebook:**  
`Multi_Linear_Regression_via_Linear_Perceptron.ipynb`

### Objective
To implement **multiple linear regression** using a perceptron-based linear model trained with a regression loss function.

### Topics Covered
- Regression vs classification concepts
- Linear forward computation (no activation)
- Mean Squared Error (MSE) loss
- Manual gradient calculation
- Gradient Descent for parameter updates
- Continuous prediction behavior

---

## ðŸ§  Key Learning Outcome

> A single linear model can be adapted for both **classification and regression** tasks by modifying the **loss function and output interpretation**, without changing the underlying model structure.

---

## ðŸ›  Tools & Technologies
- Python
- NumPy
- Pandas
- Jupyter Notebook / Google Colab

---

## ðŸ‘¤ Author
**Pooja Bisht**

---

## ðŸ“Œ Course
**UCS761 â€“ Deep Learning**
