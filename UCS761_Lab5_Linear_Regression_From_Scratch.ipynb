{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORGtDv7GKnPsgHJUeuzVDw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojabisht10/Deep-Learning/blob/main/UCS761_Lab5_Linear_Regression_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset loading"
      ],
      "metadata": {
        "id": "6HLQNPX6eJwE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l56AyTuvckq0",
        "outputId": "76cb43b0-9ff7-48d1-bf4b-6ed1b5317ae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 4177\n",
            "Column names: ['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight', 'Shucked_weight', 'Viscera_weight', 'Shell_weight', 'Rings']\n",
            "\n",
            "First 5 rows:\n",
            "  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
            "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
            "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
            "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
            "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
            "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
            "\n",
            "   Shell_weight  Rings  \n",
            "0         0.150     15  \n",
            "1         0.070      7  \n",
            "2         0.210      9  \n",
            "3         0.155     10  \n",
            "4         0.055      7  \n"
          ]
        }
      ],
      "source": [
        "# We are loading the Abalone dataset to study the relationship between physical measurements and the age of abalone.\n",
        "# This dataset is suitable because age is a continuous value and can be predicted using regression.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
        "\n",
        "columns = [\n",
        "    \"Sex\", \"Length\", \"Diameter\", \"Height\",\n",
        "    \"Whole_weight\", \"Shucked_weight\",\n",
        "    \"Viscera_weight\", \"Shell_weight\", \"Rings\"\n",
        "]\n",
        "\n",
        "data = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Print basic dataset info\n",
        "print(\"Number of rows:\", data.shape[0])\n",
        "print(\"Column names:\", list(data.columns))\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what is input:\n",
        "# The physical measurements of abalone such as length,diameter, and shell weight.\n",
        "# what is output:\n",
        "# The age of the abalone.\n",
        "# why output is numeric:\n",
        "# Age is measured in years, which is a numeric and continuous value."
      ],
      "metadata": {
        "id": "VVNNtPQEc9Tn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Target"
      ],
      "metadata": {
        "id": "161QVDqae2EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# According to problem statement:\n",
        "# Age = Rings + 1.5\n",
        "\n",
        "data[\"Age\"] = data[\"Rings\"] + 1.5\n",
        "\n",
        "y = data[\"Age\"].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "bhEE34OUdDx7"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose feature"
      ],
      "metadata": {
        "id": "3TbKh8Cve6sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting exactly 3 numeric features\n",
        "# We avoid 'Sex' because it is categorical\n",
        "\n",
        "X = data[[\"Length\", \"Diameter\", \"Shell_weight\"]].values"
      ],
      "metadata": {
        "id": "E1nGHzrAdF5E"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We select exactly three numeric features as required.\n",
        "# These features are chosen because they directly relate\n",
        "# to the physical growth of abalone.\n",
        "\n",
        "# Feature 1: Length\n",
        "#   As abalone grows older, its overall length increases.\n",
        "\n",
        "# Feature 2: Diameter\n",
        "#   Diameter gives an idea of body thickness, which also\n",
        "#   increases with age.\n",
        "\n",
        "# Feature 3: Shell_weight\n",
        "#   The shell becomes heavier as the abalone ages,\n",
        "#   making it a strong indicator of age."
      ],
      "metadata": {
        "id": "nkXJfqDJdHqG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train–Test Split"
      ],
      "metadata": {
        "id": "8WhSKE96e_g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual train-test split\n",
        "N = X.shape[0]\n",
        "split_index = int(0.8 * N)\n",
        "\n",
        "X_train = X[:split_index]\n",
        "X_test  = X[split_index:]\n",
        "\n",
        "y_train = y[:split_index]\n",
        "y_test  = y[split_index:]\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KSaQLapdKO7",
        "outputId": "8aef18f4-f500-4ffa-db48-ea3cad2f4fe0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (3341, 3)\n",
            "y_train shape: (3341, 1)\n",
            "X_test shape: (836, 3)\n",
            "y_test shape: (836, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Inputs"
      ],
      "metadata": {
        "id": "-hn9w7Z9fFMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute mean and std ONLY from training data\n",
        "mean = X_train.mean(axis=0)\n",
        "std  = X_train.std(axis=0)\n",
        "\n",
        "# Normalize train and test using training statistics\n",
        "X_train_norm = (X_train - mean) / std\n",
        "X_test_norm  = (X_test - mean) / std"
      ],
      "metadata": {
        "id": "9OF0F_-3dMkc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#why normalization is needed for learning:\n",
        "#Different features have different units and scales.\n",
        "#Without normalization, features with large values dominate the learning process.\n",
        "#Normalization helps gradient descent converge faster and more stably."
      ],
      "metadata": {
        "id": "KLBOdSupdOpO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Model (Forward Pass)"
      ],
      "metadata": {
        "id": "J3XvzJpIfIiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X, w, b):\n",
        "\n",
        "    #Computes y_hat = Xw + b\n",
        "\n",
        "    y_hat = np.dot(X, w) + b\n",
        "\n",
        "    # Print shapes once for verification\n",
        "    print(\"X shape:\", X.shape)\n",
        "    print(\"w shape:\", w.shape)\n",
        "    print(\"b shape:\", b.shape)\n",
        "    print(\"y_hat shape:\", y_hat.shape)\n",
        "\n",
        "    return y_hat"
      ],
      "metadata": {
        "id": "eZ-ruPc5dR7I"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters are:\n",
        "#   w (weights) and b (bias)\n",
        "# number of parameters:\n",
        "#   For d=3 → 3 weights + 1 bias = 4 parameters"
      ],
      "metadata": {
        "id": "2HfmOmxxdZpr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function (MSE)"
      ],
      "metadata": {
        "id": "0bH8jNM_ffBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y, y_hat):\n",
        "    #Mean Squared Error loss\n",
        "\n",
        "    loss = np.mean((y - y_hat) ** 2)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "y1NQ_ODSdbYm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# why square:\n",
        "# Squaring ensures all errors are positive and differentiable.\n",
        "# what mistakes are expensive:\n",
        "# Large errors are penalized much more than small ones."
      ],
      "metadata": {
        "id": "KvPdp7cVddQo"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what gradient means in words:\n",
        "# Gradient tells us the direction and rate at which loss increases.\n",
        "# why subtracting gradient reduces loss:\n",
        "# Moving opposite to gradient moves us downhill on the loss surface."
      ],
      "metadata": {
        "id": "YJHKjutOdfGm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Rule (Gradient Descent)"
      ],
      "metadata": {
        "id": "ogauxurzfjOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_w(X, y, y_hat):\n",
        "\n",
        "    #Gradient of loss w.r.t weights\n",
        "\n",
        "    N = X.shape[0]\n",
        "    dW = (2/N) * np.dot(X.T, (y_hat - y))\n",
        "    return dW\n",
        "\n",
        "\n",
        "def grad_b(y, y_hat):\n",
        "    \"\"\"\n",
        "    Gradient of loss w.r.t bias\n",
        "    \"\"\"\n",
        "    db = 2 * np.mean(y_hat - y)\n",
        "    return db"
      ],
      "metadata": {
        "id": "MXhx4kivdhe-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint:\n",
        "# meaning of large gradient:\n",
        "# Model is far from optimal; loss changes sharply.\n",
        "# effect of too-large learning rate:\n",
        "# Model may overshoot minimum and diverge."
      ],
      "metadata": {
        "id": "5_xNCj40djeD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "C8D0hjJsflsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters\n",
        "np.random.seed(42)\n",
        "w = np.random.randn(3, 1) * 0.01\n",
        "b = np.zeros((1,))\n",
        "\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # 1) Forward pass\n",
        "    y_hat = np.dot(X_train_norm, w) + b\n",
        "\n",
        "    # 2) Compute loss\n",
        "    loss = mse(y_train, y_hat)\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    # 3) Gradients\n",
        "    dW = grad_w(X_train_norm, y_train, y_hat)\n",
        "    db = grad_b(y_train, y_hat)\n",
        "\n",
        "    # 4) Update\n",
        "    w -= learning_rate * dW\n",
        "    b -= learning_rate * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqG_NaD5dlWX",
        "outputId": "e0ca0936-17a4-4495-d9ce-d2ae712096fd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 144.2597\n",
            "Epoch 100, Loss: 9.1999\n",
            "Epoch 200, Loss: 6.7905\n",
            "Epoch 300, Loss: 6.6844\n",
            "Epoch 400, Loss: 6.6434\n",
            "Epoch 500, Loss: 6.6182\n",
            "Epoch 600, Loss: 6.6020\n",
            "Epoch 700, Loss: 6.5913\n",
            "Epoch 800, Loss: 6.5838\n",
            "Epoch 900, Loss: 6.5783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial expectation:\n",
        "# Loss should decrease slowly but steadily.\n",
        "# Revised expectation after training:\n",
        "# Loss decreases smoothly without instability."
      ],
      "metadata": {
        "id": "tNB3kGk-dnxl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "FyRxUQ8LfpCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on test set\n",
        "y_test_hat = np.dot(X_test_norm, w) + b\n",
        "\n",
        "# Test MSE\n",
        "test_mse = mse(y_test, y_test_hat)\n",
        "\n",
        "# Test MAE\n",
        "test_mae = np.mean(np.abs(y_test - y_test_hat))\n",
        "\n",
        "print(\"Test MSE:\", test_mse)\n",
        "print(\"Test MAE:\", test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MNOs9fSdpzy",
        "outputId": "a5d8dbc4-8aea-48f5-e672-32724a088d22"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 5.117594287711015\n",
            "Test MAE: 1.7243548318088096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Predictions"
      ],
      "metadata": {
        "id": "Tv2zzz3UfrWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSample Predictions:\")\n",
        "for i in range(5):\n",
        "    print(\n",
        "        f\"True age: {y_test[i][0]:.2f}, \"\n",
        "        f\"Predicted age: {y_test_hat[i][0]:.2f}, \"\n",
        "        f\"Absolute error: {abs(y_test[i][0] - y_test_hat[i][0]):.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3nSrdPZdrlE",
        "outputId": "607f4df4-a008-4cc3-9da9-b543371e58fd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Predictions:\n",
            "True age: 13.50, Predicted age: 10.79, Absolute error: 2.71\n",
            "True age: 15.50, Predicted age: 9.65, Absolute error: 5.85\n",
            "True age: 14.50, Predicted age: 10.06, Absolute error: 4.44\n",
            "True age: 14.50, Predicted age: 11.12, Absolute error: 3.38\n",
            "True age: 13.50, Predicted age: 11.43, Absolute error: 2.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# systematic errors:\n",
        "#   The model consistently underpredicts the age of older abalones.\n",
        "# observed bias:\n",
        "#   This bias occurs because the relationship between physical measurements and age is nonlinear, while our model is linear."
      ],
      "metadata": {
        "id": "mfuNmZtXdygB"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}