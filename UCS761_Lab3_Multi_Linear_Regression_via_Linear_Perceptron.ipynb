{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojabisht10/Deep-Learning/blob/main/Multi_Linear_Regression_via_Linear_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooja Bisht"
      ],
      "metadata": {
        "id": "adxRcCuEMcLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ur64MAIw8B3w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj1ZHLpj6nU8",
        "outputId": "4c23f293-7fb3-4a8d-e85e-4c36cfe72bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  experience  income\n",
            "0   25           1   30450\n",
            "1   30           3   35670\n",
            "2   47           2   31580\n",
            "3   32           5   40130\n",
            "4   43          10   47830\n",
            "Index(['age', 'experience', 'income'], dtype='object')\n",
            "(20, 3)\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\"multiple_linear_regression_dataset.csv\")\n",
        "\n",
        "# Inspect data\n",
        "print(data.head())\n",
        "print(data.columns)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfcb5TH47BI8"
      },
      "source": [
        "Inputs (features): age, experience\n",
        "\n",
        "Output (target): income\n",
        "\n",
        "Model must learn from: 2 input features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcQnHy417IIB"
      },
      "source": [
        "# Separate Inputs and Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FvTe4Dnt61nJ"
      },
      "outputs": [],
      "source": [
        "# Inputs (features)\n",
        "X = data[[\"age\", \"experience\"]].values\n",
        "\n",
        "# Output (target)\n",
        "y = data[\"income\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Parameters Intialization"
      ],
      "metadata": {
        "id": "btf_Zsrc95wv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sbB5GO-j7OPX"
      },
      "outputs": [],
      "source": [
        "n_features = X.shape[1]\n",
        "\n",
        "# Initialize weights and bias\n",
        "w = np.zeros(n_features)\n",
        "b = 0.0\n",
        "# One weight per feature = each input affects salary differently\n",
        "\n",
        "# Bias allows prediction even when inputs are zero\n",
        "\n",
        "# Large initial values can cause unstable learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Forward pass"
      ],
      "metadata": {
        "id": "TH9kXMrt-MKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, w, b):\n",
        "    y_hat = X.dot(w) + b\n",
        "    return y_hat\n",
        "\n",
        "# No activation function because this is regression\n",
        "\n",
        "# Output can take any real value\n",
        "\n",
        "# Unlike logistic regression, we are predicting numbers, not probabilities"
      ],
      "metadata": {
        "id": "qnG-DZwO-AP4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss Function (Mean Squared Error)"
      ],
      "metadata": {
        "id": "SgRT8OVt-Z_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error(y, y_hat):\n",
        "    loss = ((y_hat - y) ** 2).mean()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "bBEvdaSX-LjF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compute Gradients"
      ],
      "metadata": {
        "id": "44qwUYY3-fmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradients(X, y, y_hat):\n",
        "    N = len(y)\n",
        "\n",
        "    dw = (2 / N) * X.T.dot(y_hat - y)\n",
        "    db = (2 / N) * (y_hat - y).sum()\n",
        "\n",
        "    return dw, db\n",
        "\n",
        "# X appears in dw because weights depend on inputs\n",
        "\n",
        "# Bias affects all samples equally, so db has no X\n",
        "\n",
        "# If error is zero, gradients are zero = learning stops"
      ],
      "metadata": {
        "id": "xYxno10j-c7S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Update Parameters (Gradient Descent)"
      ],
      "metadata": {
        "id": "lb3g6sUe-ukp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(w, b, dw, db, lr):\n",
        "    w = w - lr * dw\n",
        "    b = b - lr * db\n",
        "    return w, b\n",
        "\n",
        "# Learning rate controls step size"
      ],
      "metadata": {
        "id": "jJ4x7fxt-q43"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop"
      ],
      "metadata": {
        "id": "lsMxIMVV-4eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    y_hat = predict(X, w, b)\n",
        "    loss = mean_squared_error(y, y_hat)\n",
        "    dw, db = compute_gradients(X, y, y_hat)\n",
        "    w, b = update_parameters(w, b, dw, db, lr)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Loss should decrease over time\n",
        "\n",
        "# Increasing loss = learning rate too high\n",
        "\n",
        "# Epochs and learning rate together control convergence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzjhznvR-10s",
        "outputId": "3f35cbdb-5bb8-4362-b1dd-71fd684b1b3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1727049635.0\n",
            "Epoch 100, Loss: 66491868.55311352\n",
            "Epoch 200, Loss: 61752567.201190114\n",
            "Epoch 300, Loss: 58616531.07847049\n",
            "Epoch 400, Loss: 56528801.53951118\n",
            "Epoch 500, Loss: 55126542.02946697\n",
            "Epoch 600, Loss: 54172526.94885703\n",
            "Epoch 700, Loss: 53511656.14292054\n",
            "Epoch 800, Loss: 53042523.72795741\n",
            "Epoch 900, Loss: 52698829.56325033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Evaluation"
      ],
      "metadata": {
        "id": "9AHrBkdM_L23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final weights:\", w)\n",
        "print(\"Final bias:\", b)\n",
        "\n",
        "# Predict for a new candidate\n",
        "new_candidate = np.array([4.5, 68])\n",
        "predicted_salary = new_candidate.dot(w) + b\n",
        "print(\"Predicted Salary:\", predicted_salary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wQIuZRM_Icg",
        "outputId": "b12e6169-7a35-4f21-88d8-8b32b1d16894"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final weights: [ 764.75405919 1371.03430441]\n",
            "Final bias: 321.73641174472493\n",
            "Predicted Salary: 96993.4623777421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Is the prediction reasonable?\n",
        "\n",
        "Yes, the predicted income is reasonable because it lies within the range of values seen in the dataset and follows the trend of increasing income with experience and test score.\n",
        "\n",
        "\n",
        "#Does it interpolate smoothly?\n",
        "\n",
        "Yes, the linear model produces smooth and continuous predictions for intermediate input values.\n",
        "\n",
        "\n",
        "#Why is this better than threshold rules?\n",
        "\n",
        "This approach is better than threshold rules because it provides an exact numeric prediction instead of a coarse yes/no decision."
      ],
      "metadata": {
        "id": "M0rictis_yLr"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
